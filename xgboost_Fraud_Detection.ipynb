{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a22f7e9326944acbb6e56900ec4a38d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff837c941eb04342aea8667b3b05d252",
              "IPY_MODEL_1bef5bdf3dd147e5b1bb1a6b4e14fc1a",
              "IPY_MODEL_2a7b70b7af0a4e5b97d1794242f1deb3"
            ],
            "layout": "IPY_MODEL_7ed568f612da49309de8c44423e7dc70"
          }
        },
        "ff837c941eb04342aea8667b3b05d252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7903a6e67f0d42f4b1a847b62aaf8ebd",
            "placeholder": "​",
            "style": "IPY_MODEL_a3e0798896ab4534b6126a4e30bab1f2",
            "value": "100%"
          }
        },
        "1bef5bdf3dd147e5b1bb1a6b4e14fc1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6239ce4459f24f7589671d220b59531d",
            "max": 3680,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72f864532b034aac8dd211df39bdbbf7",
            "value": 3680
          }
        },
        "2a7b70b7af0a4e5b97d1794242f1deb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a8cc0ff9d544fcda8c530916fa73669",
            "placeholder": "​",
            "style": "IPY_MODEL_b0318ceab49443d7a7693c7e952128f7",
            "value": " 3680/3680 [32:00&lt;00:00,  2.18it/s]"
          }
        },
        "7ed568f612da49309de8c44423e7dc70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7903a6e67f0d42f4b1a847b62aaf8ebd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3e0798896ab4534b6126a4e30bab1f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6239ce4459f24f7589671d220b59531d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72f864532b034aac8dd211df39bdbbf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a8cc0ff9d544fcda8c530916fa73669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0318ceab49443d7a7693c7e952128f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lovepreetmultani/Anti-Money-Laundering/blob/main/xgboost_Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and Data load"
      ],
      "metadata": {
        "id": "ItmKCv2LpTPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "!pip install torch-geometric\n"
      ],
      "metadata": {
        "id": "oLNyDb6lc8zU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b51cdf9-2189-45e2-806a-f8dd26bb897b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=a63ff45927dc2ab95d057bc123cd9a5f95939ed0d70fda797bb74fbfd090f9b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost\n",
        "import xgboost as xgb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAxCV3s2t5eB",
        "outputId": "e5305bb8-9848-40ff-ad66-0a93469872f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (1.7.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA (GPU support for PyTorch) is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'Using GPU: {torch.cuda.get_device_name(0)}')\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('Using CPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LRib_KdYIKy",
        "outputId": "5ddc77cc-b52a-445c-d413-664fc03c846d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import time\n",
        "from datetime import datetime as dt\n",
        "from sklearn.feature_selection import  f_classif, SelectKBest\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "fFCZAY1Nb45M"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score, f1_score"
      ],
      "metadata": {
        "id": "l4D_N-xqohUZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfDJdBB7cATL",
        "outputId": "d6ed8e0a-b2ce-415e-8765-dfc3c236ec12"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fraud=pd.read_csv(\"drive/My Drive/Dissertation/Data-2-small.csv\")"
      ],
      "metadata": {
        "id": "nwTfJcTCcD6Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraud.head()"
      ],
      "metadata": {
        "id": "68eMw_aObOS7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "61ccfe4b-9256-4259-c970-816544ab2e99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   tx_fraud  tx_amount  s_pagerank   s_label  s_min_send_tx  \\\n",
              "0      True    2661.05     1.64276  52429084          90.98   \n",
              "1      True    2661.05     0.89618  37749079          90.19   \n",
              "2      True    2844.06     0.70773  34603485          90.30   \n",
              "3      True    2523.37     2.55504  49283515          91.41   \n",
              "4      True    2745.06     1.35612  55574890          90.66   \n",
              "\n",
              "   s_min_receieve_tx  s_max_send_tx  s_max_recieve_tx  s_avg_send_tx  \\\n",
              "0              45.89        2661.05           2956.72      174.60600   \n",
              "1              45.72        2661.05           2956.72      207.55542   \n",
              "2              48.52        2844.06             54.41      159.08872   \n",
              "3              45.03        2523.37           2803.73      270.59857   \n",
              "4              45.34        2745.06           2718.14      245.75222   \n",
              "\n",
              "   s_avg_recieve_tx  ...   r_label  r_min_send_tx  r_min_receieve_tx  \\\n",
              "0         314.35879  ...  52429264          91.04              46.12   \n",
              "1         437.18238  ...  52429264          91.04              46.12   \n",
              "2          52.09875  ...  47186571          90.69              45.27   \n",
              "3         139.48263  ...  34603040          90.58              45.65   \n",
              "4         320.09300  ...  57672098          90.34              45.72   \n",
              "\n",
              "   r_max_send_tx  r_max_recieve_tx  r_avg_send_tx  r_avg_recieve_tx  \\\n",
              "0         109.53           2661.05       99.75712         851.45423   \n",
              "1         109.53           2661.05       99.75712         851.45423   \n",
              "2        2559.65           2844.06      238.81746         200.33864   \n",
              "3         109.96           2662.20       99.81943         781.37258   \n",
              "4        2470.55           2745.06      314.67291         291.58139   \n",
              "\n",
              "   r_cnt_recieve_tx  r_cnt_send_tx  r_timestamp  \n",
              "0                26             52   1509580800  \n",
              "1                26             52   1509321600  \n",
              "2               103             71   1499731200  \n",
              "3                31             35   1485043200  \n",
              "4                79             55   1513987200  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bcc1d184-e58b-45cb-8651-39edac4090f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tx_fraud</th>\n",
              "      <th>tx_amount</th>\n",
              "      <th>s_pagerank</th>\n",
              "      <th>s_label</th>\n",
              "      <th>s_min_send_tx</th>\n",
              "      <th>s_min_receieve_tx</th>\n",
              "      <th>s_max_send_tx</th>\n",
              "      <th>s_max_recieve_tx</th>\n",
              "      <th>s_avg_send_tx</th>\n",
              "      <th>s_avg_recieve_tx</th>\n",
              "      <th>...</th>\n",
              "      <th>r_label</th>\n",
              "      <th>r_min_send_tx</th>\n",
              "      <th>r_min_receieve_tx</th>\n",
              "      <th>r_max_send_tx</th>\n",
              "      <th>r_max_recieve_tx</th>\n",
              "      <th>r_avg_send_tx</th>\n",
              "      <th>r_avg_recieve_tx</th>\n",
              "      <th>r_cnt_recieve_tx</th>\n",
              "      <th>r_cnt_send_tx</th>\n",
              "      <th>r_timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>True</td>\n",
              "      <td>2661.05</td>\n",
              "      <td>1.64276</td>\n",
              "      <td>52429084</td>\n",
              "      <td>90.98</td>\n",
              "      <td>45.89</td>\n",
              "      <td>2661.05</td>\n",
              "      <td>2956.72</td>\n",
              "      <td>174.60600</td>\n",
              "      <td>314.35879</td>\n",
              "      <td>...</td>\n",
              "      <td>52429264</td>\n",
              "      <td>91.04</td>\n",
              "      <td>46.12</td>\n",
              "      <td>109.53</td>\n",
              "      <td>2661.05</td>\n",
              "      <td>99.75712</td>\n",
              "      <td>851.45423</td>\n",
              "      <td>26</td>\n",
              "      <td>52</td>\n",
              "      <td>1509580800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>True</td>\n",
              "      <td>2661.05</td>\n",
              "      <td>0.89618</td>\n",
              "      <td>37749079</td>\n",
              "      <td>90.19</td>\n",
              "      <td>45.72</td>\n",
              "      <td>2661.05</td>\n",
              "      <td>2956.72</td>\n",
              "      <td>207.55542</td>\n",
              "      <td>437.18238</td>\n",
              "      <td>...</td>\n",
              "      <td>52429264</td>\n",
              "      <td>91.04</td>\n",
              "      <td>46.12</td>\n",
              "      <td>109.53</td>\n",
              "      <td>2661.05</td>\n",
              "      <td>99.75712</td>\n",
              "      <td>851.45423</td>\n",
              "      <td>26</td>\n",
              "      <td>52</td>\n",
              "      <td>1509321600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True</td>\n",
              "      <td>2844.06</td>\n",
              "      <td>0.70773</td>\n",
              "      <td>34603485</td>\n",
              "      <td>90.30</td>\n",
              "      <td>48.52</td>\n",
              "      <td>2844.06</td>\n",
              "      <td>54.41</td>\n",
              "      <td>159.08872</td>\n",
              "      <td>52.09875</td>\n",
              "      <td>...</td>\n",
              "      <td>47186571</td>\n",
              "      <td>90.69</td>\n",
              "      <td>45.27</td>\n",
              "      <td>2559.65</td>\n",
              "      <td>2844.06</td>\n",
              "      <td>238.81746</td>\n",
              "      <td>200.33864</td>\n",
              "      <td>103</td>\n",
              "      <td>71</td>\n",
              "      <td>1499731200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>True</td>\n",
              "      <td>2523.37</td>\n",
              "      <td>2.55504</td>\n",
              "      <td>49283515</td>\n",
              "      <td>91.41</td>\n",
              "      <td>45.03</td>\n",
              "      <td>2523.37</td>\n",
              "      <td>2803.73</td>\n",
              "      <td>270.59857</td>\n",
              "      <td>139.48263</td>\n",
              "      <td>...</td>\n",
              "      <td>34603040</td>\n",
              "      <td>90.58</td>\n",
              "      <td>45.65</td>\n",
              "      <td>109.96</td>\n",
              "      <td>2662.20</td>\n",
              "      <td>99.81943</td>\n",
              "      <td>781.37258</td>\n",
              "      <td>31</td>\n",
              "      <td>35</td>\n",
              "      <td>1485043200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>True</td>\n",
              "      <td>2745.06</td>\n",
              "      <td>1.35612</td>\n",
              "      <td>55574890</td>\n",
              "      <td>90.66</td>\n",
              "      <td>45.34</td>\n",
              "      <td>2745.06</td>\n",
              "      <td>2718.14</td>\n",
              "      <td>245.75222</td>\n",
              "      <td>320.09300</td>\n",
              "      <td>...</td>\n",
              "      <td>57672098</td>\n",
              "      <td>90.34</td>\n",
              "      <td>45.72</td>\n",
              "      <td>2470.55</td>\n",
              "      <td>2745.06</td>\n",
              "      <td>314.67291</td>\n",
              "      <td>291.58139</td>\n",
              "      <td>79</td>\n",
              "      <td>55</td>\n",
              "      <td>1513987200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcc1d184-e58b-45cb-8651-39edac4090f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bcc1d184-e58b-45cb-8651-39edac4090f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bcc1d184-e58b-45cb-8651-39edac4090f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-855e950e-171f-48f2-90f1-3961129d90f0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-855e950e-171f-48f2-90f1-3961129d90f0')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-855e950e-171f-48f2-90f1-3961129d90f0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fraud.columns"
      ],
      "metadata": {
        "id": "4Rx-rPwqbSQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df0979fd-4b29-44dd-fe63-d695f6e4081f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['tx_fraud', 'tx_amount', 's_pagerank', 's_label', 's_min_send_tx',\n",
              "       's_min_receieve_tx', 's_max_send_tx', 's_max_recieve_tx',\n",
              "       's_avg_send_tx', 's_avg_recieve_tx', 's_cnt_recieve_tx',\n",
              "       's_cnt_send_tx', 's_timestamp', 'r_pagerank', 'r_label',\n",
              "       'r_min_send_tx', 'r_min_receieve_tx', 'r_max_send_tx',\n",
              "       'r_max_recieve_tx', 'r_avg_send_tx', 'r_avg_recieve_tx',\n",
              "       'r_cnt_recieve_tx', 'r_cnt_send_tx', 'r_timestamp'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data balacing"
      ],
      "metadata": {
        "id": "T-hukTbDpJTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# ... Your existing imports and code for reading data ...\n",
        "\n",
        "# Features and labels before SMOTE\n",
        "features = fraud[['tx_amount', 's_pagerank', 's_label', 's_min_send_tx',\n",
        "                 's_min_receieve_tx', 's_max_send_tx', 's_max_recieve_tx',\n",
        "                 's_avg_send_tx', 's_avg_recieve_tx', 's_cnt_recieve_tx',\n",
        "                 's_cnt_send_tx', 's_timestamp', 'r_pagerank', 'r_label',\n",
        "                 'r_min_send_tx', 'r_min_receieve_tx', 'r_max_send_tx',\n",
        "                 'r_max_recieve_tx', 'r_avg_send_tx', 'r_avg_recieve_tx',\n",
        "                 'r_cnt_recieve_tx', 'r_cnt_send_tx', 'r_timestamp']]\n",
        "labels = fraud['tx_fraud']\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "features_resampled, labels_resampled = smote.fit_resample(features, labels)\n",
        "\n",
        "# Replace your original 'fraud' DataFrame with the resampled data\n",
        "fraud_resampled = features_resampled.copy()\n",
        "fraud_resampled['tx_fraud'] = labels_resampled"
      ],
      "metadata": {
        "id": "K6FkrxMJnKPL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraud_resampled['tx_fraud'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a0gXnNLp_MO",
        "outputId": "469ded44-d3f3-46f4-8c08-a2d1ad8f8eec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     9200\n",
              "False    9200\n",
              "Name: tx_fraud, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "JLoFkwjWpCmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "\n",
        "# Step 1: Map unique accounts to unique integer IDs\n",
        "unique_accounts = pd.concat([fraud_resampled['s_label'], fraud_resampled['r_label']]).drop_duplicates()\n",
        "account_to_id = {account: i for i, account in enumerate(unique_accounts)}\n",
        "\n",
        "# Step 2: Create the edge_index tensor\n",
        "source_node_indices = fraud_resampled['s_label'].map(account_to_id).values\n",
        "target_node_indices = fraud_resampled['r_label'].map(account_to_id).values\n",
        "\n",
        "edge_index = torch.tensor(\n",
        "    [\n",
        "        source_node_indices,  # Source nodes\n",
        "        target_node_indices   # Target nodes\n",
        "    ],\n",
        "    dtype=torch.long\n",
        ")"
      ],
      "metadata": {
        "id": "E1Sq70c5b1Yc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eea5dc4-05db-42b2-c9a0-dd816da5aa04"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-170449250967>:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  edge_index = torch.tensor(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Extract the features from the resampled data\n",
        "features_to_scale = ['tx_amount', 's_pagerank', 's_label', 's_min_send_tx',\n",
        "                     's_min_receieve_tx', 's_max_send_tx', 's_max_recieve_tx',\n",
        "                     's_avg_send_tx', 's_avg_recieve_tx', 's_cnt_recieve_tx',\n",
        "                     's_cnt_send_tx', 's_timestamp', 'r_pagerank', 'r_label',\n",
        "                     'r_min_send_tx', 'r_min_receieve_tx', 'r_max_send_tx',\n",
        "                     'r_max_recieve_tx', 'r_avg_send_tx', 'r_avg_recieve_tx',\n",
        "                     'r_cnt_recieve_tx', 'r_cnt_send_tx', 'r_timestamp']\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Apply scaling to the features\n",
        "fraud_data_scaled = fraud_resampled.copy()\n",
        "fraud_data_scaled[features_to_scale] = scaler.fit_transform(fraud_resampled[features_to_scale])\n",
        "\n",
        "\n",
        "# Use the scaled features in the resampled dataset\n",
        "fraud_resampled_scaled = fraud_data_scaled.copy()\n",
        "\n",
        "# Node features for the sender and receiver\n",
        "sender_features_scaled = torch.tensor(fraud_resampled_scaled[['s_pagerank', 's_label', 's_min_send_tx',\n",
        "                                  's_min_receieve_tx', 's_max_send_tx', 's_max_recieve_tx',\n",
        "                                  's_avg_send_tx', 's_avg_recieve_tx', 's_cnt_recieve_tx',\n",
        "                                  's_cnt_send_tx', 's_timestamp']].values, dtype=torch.float)\n",
        "\n",
        "receiver_features_scaled = torch.tensor(fraud_resampled_scaled[['r_pagerank', 'r_label', 'r_min_send_tx',\n",
        "                                    'r_min_receieve_tx', 'r_max_send_tx', 'r_max_recieve_tx',\n",
        "                                    'r_avg_send_tx', 'r_avg_recieve_tx', 'r_cnt_recieve_tx',\n",
        "                                    'r_cnt_send_tx', 'r_timestamp']].values, dtype=torch.float)\n",
        "\n",
        "# Combining the sender and receiver features\n",
        "x_scaled = torch.cat([sender_features_scaled, receiver_features_scaled], dim=1)\n",
        "\n",
        "# Edge features\n",
        "edge_attr_scaled = torch.tensor(fraud_resampled_scaled[['tx_amount']].values, dtype=torch.float)\n",
        "\n",
        "# Create a PyTorch Geometric data object with scaled features\n",
        "data_scaled = Data(x=x_scaled, edge_index=edge_index, edge_attr=edge_attr_scaled)\n"
      ],
      "metadata": {
        "id": "NGz49bToFM2x"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "SFTHXIY7t6Pw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test train split"
      ],
      "metadata": {
        "id": "kXa0nXa3uO8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Initial train-test split\n",
        "train_fraud, temp_fraud = train_test_split(fraud_resampled_scaled, test_size=0.4, random_state=42, stratify=fraud_resampled_scaled['tx_fraud'])\n",
        "\n",
        "# Split the remaining 40% into validation and test sets\n",
        "val_fraud, test_fraud = train_test_split(temp_fraud, test_size=0.5, random_state=42, stratify=temp_fraud['tx_fraud'])"
      ],
      "metadata": {
        "id": "6L61QYVVrknD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = fraud_resampled_scaled.loc[train_fraud.index, features_to_scale]\n",
        "y_train = fraud_resampled_scaled.loc[train_fraud.index, 'tx_fraud']\n",
        "\n",
        "X_val = fraud_resampled_scaled.loc[val_fraud.index, features_to_scale]\n",
        "y_val = fraud_resampled_scaled.loc[val_fraud.index, 'tx_fraud']\n",
        "\n",
        "X_test = fraud_resampled_scaled.loc[test_fraud.index, features_to_scale]\n",
        "y_test = fraud_resampled_scaled.loc[test_fraud.index, 'tx_fraud']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FdwhY0IhuOCr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install explainerdashboard\n",
        "from explainerdashboard import ClassifierExplainer, ExplainerDashboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3fkHFcMLPum8",
        "outputId": "b33f1dc2-6b0a-4929-a7bf-4b668d0f3ae8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting explainerdashboard\n",
            "  Downloading explainerdashboard-0.4.3-py3-none-any.whl (287 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/287.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m204.8/287.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from explainerdashboard) (8.1.7)\n",
            "Collecting dash-auth (from explainerdashboard)\n",
            "  Downloading dash_auth-2.0.0-py3-none-any.whl (3.4 kB)\n",
            "Collecting dash-bootstrap-components>=1 (from explainerdashboard)\n",
            "  Downloading dash_bootstrap_components-1.5.0-py3-none-any.whl (221 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.2/221.2 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dash>=2.10.1 (from explainerdashboard)\n",
            "  Downloading dash-2.13.0-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dtreeviz>=2.1 (from explainerdashboard)\n",
            "  Downloading dtreeviz-2.2.2-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flask-simplelogin (from explainerdashboard)\n",
            "  Downloading flask_simplelogin-0.1.2-py3-none-any.whl (7.2 kB)\n",
            "Collecting Flask-WTF>=1.1 (from explainerdashboard)\n",
            "  Downloading Flask_WTF-1.1.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: graphviz>=0.18.2 in /usr/local/lib/python3.10/dist-packages (from explainerdashboard) (0.20.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from explainerdashboard) (1.3.2)\n",
            "Collecting jupyter-dash>=0.4.1 (from explainerdashboard)\n",
            "  Downloading jupyter_dash-0.4.2-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy<=1.24.4 in /usr/local/lib/python3.10/dist-packages (from explainerdashboard) (1.23.5)\n",
            "Collecting oyaml (from explainerdashboard)\n",
            "  Downloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
            "Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.10/dist-packages (from explainerdashboard) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1 in /usr/local/lib/python3.10/dist-packages (from explainerdashboard) (1.2.2)\n",
            "Collecting shap>=0.42.1 (from explainerdashboard)\n",
            "  Downloading shap-0.42.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.9/547.9 kB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting waitress (from explainerdashboard)\n",
            "  Downloading waitress-2.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<2.3.0,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.10.1->explainerdashboard) (2.2.5)\n",
            "Collecting Werkzeug<2.3.0 (from dash>=2.10.1->explainerdashboard)\n",
            "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.10.1->explainerdashboard) (5.15.0)\n",
            "Collecting dash-html-components==2.0.0 (from dash>=2.10.1->explainerdashboard)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash>=2.10.1->explainerdashboard)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting dash-table==5.0.0 (from dash>=2.10.1->explainerdashboard)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.10.1->explainerdashboard) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash>=2.10.1->explainerdashboard) (2.31.0)\n",
            "Collecting retrying (from dash>=2.10.1->explainerdashboard)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Collecting ansi2html (from dash>=2.10.1->explainerdashboard)\n",
            "  Downloading ansi2html-1.8.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.10.1->explainerdashboard) (1.5.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash>=2.10.1->explainerdashboard) (67.7.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from dtreeviz>=2.1->explainerdashboard) (3.7.1)\n",
            "Requirement already satisfied: colour in /usr/local/lib/python3.10/dist-packages (from dtreeviz>=2.1->explainerdashboard) (0.1.5)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from dtreeviz>=2.1->explainerdashboard) (7.4.1)\n",
            "Collecting WTForms (from Flask-WTF>=1.1->explainerdashboard)\n",
            "  Downloading WTForms-3.0.1-py3-none-any.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.5/136.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: itsdangerous in /usr/local/lib/python3.10/dist-packages (from Flask-WTF>=1.1->explainerdashboard) (2.1.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from jupyter-dash>=0.4.1->explainerdashboard) (7.34.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter-dash>=0.4.1->explainerdashboard) (5.5.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->explainerdashboard) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->explainerdashboard) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1->explainerdashboard) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1->explainerdashboard) (3.2.0)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap>=0.42.1->explainerdashboard) (4.66.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap>=0.42.1->explainerdashboard) (23.1)\n",
            "Collecting slicer==0.0.7 (from shap>=0.42.1->explainerdashboard)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap>=0.42.1->explainerdashboard) (0.56.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap>=0.42.1->explainerdashboard) (2.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from oyaml->explainerdashboard) (6.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<2.3.0,>=1.0.4->dash>=2.10.1->explainerdashboard) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.10.1->explainerdashboard) (8.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1->explainerdashboard) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug<2.3.0->dash>=2.10.1->explainerdashboard) (2.1.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter-dash>=0.4.1->explainerdashboard) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter-dash>=0.4.1->explainerdashboard) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter-dash>=0.4.1->explainerdashboard) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter-dash>=0.4.1->explainerdashboard) (6.3.2)\n",
            "Collecting jedi>=0.16 (from ipython->jupyter-dash>=0.4.1->explainerdashboard)\n",
            "  Downloading jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash>=0.4.1->explainerdashboard) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash>=0.4.1->explainerdashboard) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash>=0.4.1->explainerdashboard) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash>=0.4.1->explainerdashboard) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash>=0.4.1->explainerdashboard) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash>=0.4.1->explainerdashboard) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash>=0.4.1->explainerdashboard) (4.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dtreeviz>=2.1->explainerdashboard) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dtreeviz>=2.1->explainerdashboard) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dtreeviz>=2.1->explainerdashboard) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dtreeviz>=2.1->explainerdashboard) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dtreeviz>=2.1->explainerdashboard) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dtreeviz>=2.1->explainerdashboard) (3.1.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap>=0.42.1->explainerdashboard) (0.39.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->dtreeviz>=2.1->explainerdashboard) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->dtreeviz>=2.1->explainerdashboard) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->dtreeviz>=2.1->explainerdashboard) (1.1.3)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->dtreeviz>=2.1->explainerdashboard) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.10.1->explainerdashboard) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.10.1->explainerdashboard) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.10.1->explainerdashboard) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.10.1->explainerdashboard) (2023.7.22)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->jupyter-dash>=0.4.1->explainerdashboard) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->jupyter-dash>=0.4.1->explainerdashboard) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyter-dash>=0.4.1->explainerdashboard) (0.2.6)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->jupyter-dash>=0.4.1->explainerdashboard) (5.3.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->jupyter-dash>=0.4.1->explainerdashboard) (23.2.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->jupyter-dash>=0.4.1->explainerdashboard) (3.10.0)\n",
            "Installing collected packages: dash-table, dash-html-components, dash-core-components, WTForms, Werkzeug, waitress, slicer, retrying, oyaml, jedi, ansi2html, shap, Flask-WTF, dtreeviz, dash, jupyter-dash, flask-simplelogin, dash-bootstrap-components, dash-auth, explainerdashboard\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 2.3.7\n",
            "    Uninstalling Werkzeug-2.3.7:\n",
            "      Successfully uninstalled Werkzeug-2.3.7\n",
            "Successfully installed Flask-WTF-1.1.1 WTForms-3.0.1 Werkzeug-2.2.3 ansi2html-1.8.0 dash-2.13.0 dash-auth-2.0.0 dash-bootstrap-components-1.5.0 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 dtreeviz-2.2.2 explainerdashboard-0.4.3 flask-simplelogin-0.1.2 jedi-0.19.0 jupyter-dash-0.4.2 oyaml-1.0 retrying-1.3.4 shap-0.42.1 slicer-0.0.7 waitress-2.1.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "YOWeCKEYueCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBRFClassifier\n",
        "from sklearn.metrics import precision_score\n",
        "from pathlib import Path\n",
        "pkl_dir = Path.cwd() / \"pkls\"\n",
        "\n",
        "# Define the parameter grid for XGBoost\n",
        "param_grid = {\n",
        "    'n_estimators': [10],\n",
        "    'max_depth': [3, 4],\n",
        "    'learning_rate': [0.001],\n",
        "    'gamma': [0],\n",
        "    'min_child_weight': [1],\n",
        "    'booster': ['gbtree']\n",
        "}\n",
        "\n",
        "# Initialize the XGBoost model\n",
        "xgb_model = XGBRFClassifier(use_label_encoder=False, n_jobs=-1, max_depth= 5, min_child_weight=10, gamma=1, scale_pos_weight=99, max_delta_step=1, eval_metric='logloss')\n",
        "\n",
        "# Set up the grid search with 5-fold cross validation\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid,\n",
        "                           scoring='precision', cv=5, verbose=2, n_jobs=-1)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "class_explainer = ClassifierExplainer(xgb_model, X_test, y_test,\n",
        "                               labels=['Normal', 'Fraud'])\n",
        "_ = ExplainerDashboard(class_explainer)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "# Train and evaluate the best model\n",
        "best_xgb = grid_search.best_estimator_\n",
        "\n",
        "# Making predictions on the test set using the best XGBoost model\n",
        "xgb_test_predictions = best_xgb.predict(X_test)\n",
        "\n",
        "# Evaluate using Precision on the test set\n",
        "xgb_test_precision = precision_score(y_test, xgb_test_predictions)\n",
        "print(f\"XGBoost Test Precision with best model: {xgb_test_precision}\")\n",
        "\n",
        "# Making predictions on the validation set using the best XGBoost model\n",
        "xgb_val_predictions = best_xgb.predict(X_val)\n",
        "\n",
        "# Evaluate using Precision on the validation set\n",
        "xgb_val_precision = precision_score(y_val, xgb_val_predictions)\n",
        "print(f\"XGBoost Validation Precision with best model: {xgb_val_precision}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891,
          "referenced_widgets": [
            "a22f7e9326944acbb6e56900ec4a38d0",
            "ff837c941eb04342aea8667b3b05d252",
            "1bef5bdf3dd147e5b1bb1a6b4e14fc1a",
            "2a7b70b7af0a4e5b97d1794242f1deb3",
            "7ed568f612da49309de8c44423e7dc70",
            "7903a6e67f0d42f4b1a847b62aaf8ebd",
            "a3e0798896ab4534b6126a4e30bab1f2",
            "6239ce4459f24f7589671d220b59531d",
            "72f864532b034aac8dd211df39bdbbf7",
            "2a8cc0ff9d544fcda8c530916fa73669",
            "b0318ceab49443d7a7693c7e952128f7"
          ]
        },
        "id": "m2Ib0TK8fpK_",
        "outputId": "ec4c694b-73e7-4bb9-82d5-b0e9326933d9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:1395: UserWarning:\n",
            "\n",
            "`use_label_encoder` is deprecated in 1.7.0.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Parameter shap='guess', but failed to guess the type of shap explainer to use for XGBRFClassifier. Defaulting to the model agnostic shap.KernelExplainer (shap='kernel'). However this will be slow, so if your model is compatible with e.g. shap.TreeExplainer or shap.LinearExplainer then pass shap='tree' or shap='linear'!\n",
            "WARNING: For shap='kernel', shap interaction values can unfortunately not be calculated!\n",
            "Note: shap values for shap='kernel' normally get calculated against X_background, but paramater X_background=None, so setting X_background=shap.sample(X, 50)...\n",
            "Generating self.shap_explainer = shap.KernelExplainer(model, X, link='identity')\n",
            "Building ExplainerDashboard..\n",
            "WARNING: the number of idxs (=3680) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.13.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
            "Detected google colab environment, setting mode='external'\n",
            "For this type of model and model_output interactions don't work, so setting shap_interaction=False...\n",
            "The explainer object has no decision_trees property. so setting decision_trees=False...\n",
            "Generating layout...\n",
            "Calculating shap values...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dash/dash.py:525: UserWarning:\n",
            "\n",
            "JupyterDash is deprecated, use Dash instead.\n",
            "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3680 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a22f7e9326944acbb6e56900ec4a38d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating prediction probabilities...\n",
            "Calculating metrics...\n",
            "Calculating confusion matrices...\n",
            "Calculating classification_dfs...\n",
            "Calculating roc auc curves...\n",
            "Calculating pr auc curves...\n",
            "Calculating liftcurve_dfs...\n",
            "Calculating dependencies...\n",
            "Calculating permutation importances (if slow, try setting n_jobs parameter)...\n",
            "Calculating pred_percentiles...\n",
            "Calculating predictions...\n",
            "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
            "Registering callbacks...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-067105a7abae>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Get the best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best parameters: {best_params}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttreeshap\n",
        "shap_explainer = fasttreeshap.TreeExplainer(xgb_model)"
      ],
      "metadata": {
        "id": "P7SaMfPmdD3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score, f1_score\n",
        "x_result = confusion_matrix(y_test, xgb_test_predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(x_result)\n",
        "print('\\n')\n",
        "result1 = classification_report(y_test, xgb_test_predictions)\n",
        "print(\"Classification Report:\",)\n",
        "print (result1)\n",
        "print('\\n')\n",
        "x_result2 = accuracy_score(y_test,xgb_test_predictions)\n",
        "print(\"Accuracy:\",x_result2)\n",
        "print('\\n')\n",
        "# calculate precision and recall scores\n",
        "x_precision = precision_score(y_test, xgb_test_predictions)\n",
        "x_recall = recall_score(y_test, xgb_test_predictions)\n",
        "x_f1score = f1_score(y_test, xgb_test_predictions)\n",
        "\n",
        "# print the results\n",
        "print(\"Precision:\", x_precision)\n",
        "print(\"Recall:\", x_recall)\n",
        "print(\"f1 score:\", x_f1score)\n",
        "\n",
        "print(roc_auc_score(y_test, xgb_test_predictions))\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, xgb_test_predictions)\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FmLcel27xCEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import plot_importance, to_graphviz\n",
        "fig = plt.figure(figsize = (5, 3))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "colours = plt.cm.Set1(np.linspace(0, 1, 9))\n",
        "\n",
        "ax = plot_importance(xgb_model, height = 1, color = colours, grid = False, \\\n",
        "                     show_values = False, importance_type = 'cover', ax = ax);\n",
        "for axis in ['top','bottom','left','right']:\n",
        "            ax.spines[axis].set_linewidth(2)\n",
        "\n",
        "ax.set_xlabel('importance score', size = 16);\n",
        "ax.set_ylabel('features', size = 16);\n",
        "ax.set_yticklabels(ax.get_yticklabels(), size = 12);\n",
        "ax.set_title('Ordering of features by importance to the model learnt', size = 20);\n",
        "to_graphviz(xgb_model)"
      ],
      "metadata": {
        "id": "bYswx3wF9RiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN"
      ],
      "metadata": {
        "id": "XwJj5ig7p2j4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Define the parameter grid for KNN\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "}\n",
        "\n",
        "# Initialize the KNN model\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "# Set up the grid search with 5-fold cross validation\n",
        "grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid,\n",
        "                           scoring='precision', cv=5, verbose=2, n_jobs=-1)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "# Train and evaluate the best model\n",
        "best_knn = grid_search.best_estimator_\n",
        "\n",
        "# Making predictions on the test set using the best KNN model\n",
        "knn_test_predictions = best_knn.predict(X_test)\n",
        "\n",
        "# Evaluate using Precision on the test set\n",
        "knn_test_precision = precision_score(y_test, knn_test_predictions)\n",
        "print(f\"KNN Test Precision with best model: {knn_test_precision}\")\n",
        "\n",
        "# Making predictions on the validation set using the best KNN model\n",
        "knn_val_predictions = best_knn.predict(X_val)\n",
        "\n",
        "# Evaluate using Precision on the validation set\n",
        "knn_val_precision = precision_score(y_val, knn_val_predictions)\n",
        "print(f\"KNN Validation Precision with best model: {knn_val_precision}\")\n"
      ],
      "metadata": {
        "id": "TC_pn1wjh3o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score, f1_score\n",
        "k_result = confusion_matrix(y_test, knn_test_predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(k_result)\n",
        "print('\\n')\n",
        "result1 = classification_report(y_test, knn_test_predictions)\n",
        "print(\"Classification Report:\",)\n",
        "print (result1)\n",
        "print('\\n')\n",
        "k_result2 = accuracy_score(y_test,knn_test_predictions)\n",
        "print(\"Accuracy:\",k_result2)\n",
        "print('\\n')\n",
        "# calculate precision and recall scores\n",
        "k_precision = precision_score(y_test, knn_test_predictions)\n",
        "k_recall = recall_score(y_test, knn_test_predictions)\n",
        "k_f1score = f1_score(y_test, knn_test_predictions)\n",
        "\n",
        "# print the results\n",
        "print(\"Precision:\", k_precision)\n",
        "print(\"Recall:\", k_recall)\n",
        "print(\"f1 score:\", k_f1score)\n",
        "\n",
        "print(roc_auc_score(y_test, knn_test_predictions))\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, knn_test_predictions)\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8UKKjo_as0m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Decision Tree"
      ],
      "metadata": {
        "id": "Jg4AfnQEd049"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Define the parameter grid for Decision Tree\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 3, 5, 7, 9, 11],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Initialize the Decision Tree model\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Set up the grid search with 5-fold cross validation\n",
        "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid,\n",
        "                           scoring='precision', cv=5, verbose=2, n_jobs=-1)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "# Train and evaluate the best model\n",
        "best_dt = grid_search.best_estimator_\n",
        "\n",
        "# Making predictions on the validation set using the best Decision Tree model\n",
        "dt_val_predictions = best_dt.predict(X_val)\n",
        "\n",
        "# Evaluate using Precision on the validation set\n",
        "dt_val_precision = precision_score(y_val, dt_val_predictions)\n",
        "print(f\"Decision Tree Validation Precision with best model: {dt_val_precision}\")\n",
        "\n",
        "# Making predictions on the test set using the best Decision Tree model\n",
        "dt_test_predictions = best_dt.predict(X_test)\n",
        "\n",
        "# Evaluate using Precision on the test set\n",
        "dt_test_precision = precision_score(y_test, dt_test_predictions)\n",
        "print(f\"Decision Tree Test Precision with best model: {dt_test_precision}\")\n"
      ],
      "metadata": {
        "id": "Eeiw0hokd0Va",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "d7c98193-9ab7-4fcf-af5c-a866773af030"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Note: model_output=='probability', so assuming that raw shap output of DecisionTreeClassifier is in probability space...\n",
            "Generating self.shap_explainer = shap.TreeExplainer(model)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-252fcec16da3>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m class_explainer = ClassifierExplainer(dt_model, X_test, y_test,\n\u001b[0m\u001b[1;32m     24\u001b[0m                                labels=['Normal', 'Fraud'])\n\u001b[1;32m     25\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExplainerDashboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_explainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/explainerdashboard/explainers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, X, y, permutation_metric, shap, X_background, model_output, cats, cats_notencoded, idxs, index_name, target, descriptions, n_jobs, permutation_cv, cv, na_fill, precision, shap_kwargs, labels, pos_label)\u001b[0m\n\u001b[1;32m   2505\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"logodds\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2507\u001b[0;31m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_explainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2509\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/explainerdashboard/explainers.py\u001b[0m in \u001b[0;36mshap_explainer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2687\u001b[0m                         \u001b[0;34mf\"Generating self.shap_explainer = shap.TreeExplainer(model{', X_background' if self.X_background is not None else ''})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2688\u001b[0m                     )\n\u001b[0;32m-> 2689\u001b[0;31m                     self._shap_explainer = shap.TreeExplainer(\n\u001b[0m\u001b[1;32m   2690\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_background\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, model_output, feature_perturbation, feature_names, approximate, **deprecated_options)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_perturbation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_perturbation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTreeEnsemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_missing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m#self.model_output = self.model.model_output # this allows the TreeEnsemble to translate model outputs types by how it loads the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, data_missing, model_output)\u001b[0m\n\u001b[1;32m    741\u001b[0m             ],\n\u001b[1;32m    742\u001b[0m         ):\n\u001b[0;32m--> 743\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSingleTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DecisionTreeClassifier' object has no attribute 'tree_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score, f1_score\n",
        "dt_result = confusion_matrix(y_test, dt_test_predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(dt_result)\n",
        "print('\\n')\n",
        "result1 = classification_report(y_test, dt_test_predictions)\n",
        "print(\"Classification Report:\",)\n",
        "print (result1)\n",
        "print('\\n')\n",
        "d_result2 = accuracy_score(y_test,dt_test_predictions)\n",
        "print(\"Accuracy:\",d_result2)\n",
        "print('\\n')\n",
        "# calculate precision and recall scores\n",
        "d_precision = precision_score(y_test, dt_test_predictions)\n",
        "d_recall = recall_score(y_test, dt_test_predictions)\n",
        "d_f1score = f1_score(y_test, dt_test_predictions)\n",
        "\n",
        "# print the results\n",
        "print(\"Precision:\", d_precision)\n",
        "print(\"Recall:\", d_recall)\n",
        "print(\"f1 score:\", d_f1score)\n",
        "\n",
        "print(\"ROC AUC Score\",roc_auc_score(y_test, dt_test_predictions))\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, dt_test_predictions)\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8cxqzYOrfD8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RANDOM FOREST"
      ],
      "metadata": {
        "id": "JVKxAkCpUWL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Define the parameter grid for Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=10, random_state=42,max_depth=5,class_weight='balanced')\n",
        "\n",
        "# Set up the grid search with 5-fold cross validation\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid,\n",
        "                           scoring='precision', cv=5, verbose=2, n_jobs=-1)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "# Train and evaluate the best model\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# Making predictions on the validation set using the best Random Forest model\n",
        "rf_val_predictions = best_rf.predict(X_val)\n",
        "\n",
        "# Evaluate using Precision on the validation set\n",
        "rf_val_precision = precision_score(y_val, rf_val_predictions)\n",
        "print(f\"Random Forest Validation Precision with best model: {rf_val_precision}\")\n",
        "\n",
        "# Making predictions on the test set using the best Random Forest model\n",
        "rf_test_predictions = best_rf.predict(X_test)\n",
        "\n",
        "# Evaluate using Precision on the test set\n",
        "rf_test_precision = precision_score(y_test, rf_test_predictions)\n",
        "print(f\"Random Forest Test Precision with best model: {rf_test_precision}\")\n"
      ],
      "metadata": {
        "id": "CkerZ0h7RTEM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "7851158f-7b02-4b3f-c98f-6ab90674b381"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-4018b51b939b>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Fit the grid search to the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Get the best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1705\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1706\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Define the parameter grid for Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=10, random_state=42,max_depth=5,class_weight='balanced')\n",
        "\n",
        "# Set up the grid search with 5-fold cross validation\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid,\n",
        "                           scoring='precision', cv=5, verbose=2, n_jobs=-1)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "class_explainer = ClassifierExplainer(rf_model, X_test, y_test,\n",
        "                               labels=['Normal', 'Fraud'])\n",
        "_ = ExplainerDashboard(class_explainer)"
      ],
      "metadata": {
        "id": "DGO66eL1jRaT",
        "outputId": "87a13163-1bd6-4a6f-9e0e-0bfe2075721e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected RandomForestClassifier model: Changing class type to RandomForestClassifierExplainer...\n",
            "Note: model_output=='probability', so assuming that raw shap output of RandomForestClassifier is in probability space...\n",
            "Generating self.shap_explainer = shap.TreeExplainer(model)\n",
            "Building ExplainerDashboard..\n",
            "WARNING: the number of idxs (=3680) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.13.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
            "Detected google colab environment, setting mode='external'\n",
            "Warning: calculating shap interaction values can be slow! Pass shap_interaction=False to remove interactions tab.\n",
            "Generating layout...\n",
            "Calculating shap values...\n",
            "Calculating prediction probabilities...\n",
            "Calculating metrics...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dash/dash.py:525: UserWarning:\n",
            "\n",
            "JupyterDash is deprecated, use Dash instead.\n",
            "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating confusion matrices...\n",
            "Calculating classification_dfs...\n",
            "Calculating roc auc curves...\n",
            "Calculating pr auc curves...\n",
            "Calculating liftcurve_dfs...\n",
            "Calculating shap interaction values... (this may take a while)\n",
            "Reminder: TreeShap computational complexity is O(TLD^2), where T is the number of trees, L is the maximum number of leaves in any tree and D the maximal depth of any tree. So reducing these will speed up the calculation.\n",
            "Calculating dependencies...\n",
            "Calculating permutation importances (if slow, try setting n_jobs parameter)...\n",
            "Calculating pred_percentiles...\n",
            "Calculating predictions...\n",
            "Calculating ShadowDecTree for each individual decision tree...\n",
            "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
            "Registering callbacks...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db = ExplainerDashboard(class_explainer,\n",
        "                    whatif=False, # you can switch off tabs with bools\n",
        "                    shap_interaction=False,\n",
        "                    decision_trees=False)\n",
        "db.run(port=8051)"
      ],
      "metadata": {
        "id": "UCGntIF_jvJW",
        "outputId": "fc0c31cc-123f-4d07-cd75-09a720bbcccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building ExplainerDashboard..\n",
            "WARNING: the number of idxs (=3680) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.13.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
            "Detected google colab environment, setting mode='external'\n",
            "Generating layout...\n",
            "Calculating dependencies...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dash/dash.py:525: UserWarning:\n",
            "\n",
            "JupyterDash is deprecated, use Dash instead.\n",
            "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
            "Registering callbacks...\n",
            "Starting ExplainerDashboard on http://172.28.0.12:8051\n",
            "You can terminate the dashboard with ExplainerDashboard.terminate(8051)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8051, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dash app running on:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(8051, \"/\", \"http://127.0.0.1:8051/\", window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_result = confusion_matrix(y_test, rf_test_predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(rf_result)\n",
        "print('\\n')\n",
        "result1 = classification_report(y_test, rf_test_predictions)\n",
        "print(\"Classification Report:\",)\n",
        "print(result1)\n",
        "print('\\n')\n",
        "rf_result2 = accuracy_score(y_test, rf_test_predictions)\n",
        "print(\"Accuracy:\", rf_result2)\n",
        "print('\\n')\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "rf_precision = precision_score(y_test, rf_test_predictions)\n",
        "rf_recall = recall_score(y_test, rf_test_predictions)\n",
        "rf_f1score = f1_score(y_test, rf_test_predictions)\n",
        "\n",
        "# Print the results\n",
        "print(\"Precision:\", rf_precision)\n",
        "print(\"Recall:\", rf_recall)\n",
        "print(\"f1 score:\", rf_f1score)\n",
        "print(roc_auc_score(y_test, rf_test_predictions))\n",
        "\n",
        "# Plot ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, rf_test_predictions)\n",
        "plt.clf()\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5GzB3PGFUYvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nO__VuhERTXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GNN\n"
      ],
      "metadata": {
        "id": "8phdKSM3bxco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model building"
      ],
      "metadata": {
        "id": "ExQZUWFzfHEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv"
      ],
      "metadata": {
        "id": "q0bnXG24qqOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNModel(torch.nn.Module):\n",
        "    def __init__(self, num_node_features):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.conv1 = GCNConv(num_node_features, 32)  # Increased from 16 to 32\n",
        "        self.conv2 = GCNConv(32, 16)  # New layer\n",
        "        self.conv3 = GCNConv(16, 2)  # Output layer\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)  # New layer\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "BdQ4VzCzMfuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test train split"
      ],
      "metadata": {
        "id": "Og7KE5KIfvTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Initial train-test split\n",
        "train_fraud, temp_fraud = train_test_split(fraud_resampled_scaled, test_size=0.4, random_state=42, stratify=fraud_resampled_scaled['tx_fraud'])\n",
        "\n",
        "# Split the remaining 40% into validation and test sets\n",
        "val_fraud, test_fraud = train_test_split(temp_fraud, test_size=0.5, random_state=42, stratify=temp_fraud['tx_fraud'])\n",
        "\n",
        "# Initialize masks\n",
        "train_mask = torch.zeros(len(fraud_resampled_scaled), dtype=torch.bool)\n",
        "val_mask = torch.zeros(len(fraud_resampled_scaled), dtype=torch.bool)\n",
        "test_mask = torch.zeros(len(fraud_resampled_scaled), dtype=torch.bool)\n",
        "\n",
        "# Update masks based on the indices of the train, validation and test sets\n",
        "train_mask[train_fraud.index] = True\n",
        "val_mask[val_fraud.index] = True\n",
        "test_mask[test_fraud.index] = True\n",
        "\n",
        "# Update your data object\n",
        "data_scaled.train_mask = train_mask\n",
        "data_scaled.val_mask = val_mask\n",
        "data_scaled.test_mask = test_mask\n",
        "data_scaled.y = torch.tensor(fraud_resampled_scaled['tx_fraud'].values, dtype=torch.long)"
      ],
      "metadata": {
        "id": "eXFqbVBdfMuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "e-IdIPtTh70D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of node features\n",
        "num_node_features = x_scaled.shape[1]"
      ],
      "metadata": {
        "id": "mw8XicY6kJ5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Define the model, optimizer, and hyperparameters\n",
        "def create_model_and_optimizer(learning_rate):\n",
        "    GN_model = GNNModel(data_scaled.num_node_features)\n",
        "    optimizer = torch.optim.Adam(GN_model.parameters(), lr=learning_rate)\n",
        "    return GN_model, optimizer\n",
        "\n",
        "# Grid of hyperparameters to search over\n",
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "epochs_list = [50, 100, 200]\n",
        "\n",
        "best_val_precision = 0\n",
        "best_hyperparams = {}\n",
        "\n",
        "# Manual grid search\n",
        "for lr in learning_rates:\n",
        "    for epochs in epochs_list:\n",
        "        GN_model, optimizer = create_model_and_optimizer(lr)\n",
        "\n",
        "        # Training loop with validation\n",
        "        for epoch in range(epochs):\n",
        "            GN_model.train()\n",
        "            optimizer.zero_grad()\n",
        "            out = GN_model(data_scaled)\n",
        "\n",
        "            # Training loss\n",
        "            train_loss = F.nll_loss(out[data_scaled.train_mask], data_scaled.y[data_scaled.train_mask])\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate training precision\n",
        "            _, train_pred = out[data_scaled.train_mask].max(dim=1)\n",
        "            train_true = data_scaled.y[data_scaled.train_mask]\n",
        "            train_precision = precision_score(train_true.cpu(), train_pred.cpu(), average='micro')\n",
        "\n",
        "            # Validation\n",
        "            GN_model.eval()  # Set the model to evaluation mode\n",
        "            with torch.no_grad():  # Deactivate autograd engine to reduce memory usage and speed up computations\n",
        "                val_loss = F.nll_loss(out[data_scaled.val_mask], data_scaled.y[data_scaled.val_mask])\n",
        "\n",
        "                # Calculate validation precision\n",
        "                _, val_pred = out[data_scaled.val_mask].max(dim=1)\n",
        "                val_true = data_scaled.y[data_scaled.val_mask]\n",
        "                val_precision = precision_score(val_true.cpu(), val_pred.cpu(), average='micro')\n",
        "\n",
        "            # Print the metrics for every epoch\n",
        "            print(f\"LR: {lr}, Epochs: {epochs}, Epoch {epoch+1}, Training Loss: {train_loss.item()}, Validation Loss: {val_loss.item()}, Training Precision: {train_precision}, Validation Precision: {val_precision}\")\n",
        "\n",
        "        # At the end of training, check if the validation precision is the best so far\n",
        "        if val_precision > best_val_precision:\n",
        "            best_val_precision = val_precision\n",
        "            best_hyperparams = {'learning_rate': lr, 'epochs': epochs}\n",
        "\n",
        "print(f\"Best Validation Precision: {best_val_precision}\")\n",
        "print(f\"Best Hyperparameters: {best_hyperparams}\")\n"
      ],
      "metadata": {
        "id": "kpzaYYSZh12z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing and Evaluation\n",
        "GN_model.eval()\n",
        "_, pred = out.max(dim=1)\n",
        "correct = float(pred[data_scaled.test_mask].eq(data_scaled.y[data_scaled.test_mask]).sum().item())\n",
        "acc = correct / data_scaled.test_mask.sum().item()\n",
        "print(f\"Test Accuracy: {acc}\")\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "\n",
        "# Testing and Evaluation\n",
        "GN_model.eval()\n",
        "_, pred = out.max(dim=1)\n",
        "\n",
        "# Extract ground truth and predictions for test set\n",
        "true_labels = data_scaled.y[data_scaled.test_mask].cpu().numpy()\n",
        "predicted_labels = pred[data_scaled.test_mask].cpu().numpy()"
      ],
      "metadata": {
        "id": "twp_PyW5v8-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "g_result = confusion_matrix(true_labels, predicted_labels)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(g_result)\n",
        "print('\\n')\n",
        "result1 = classification_report(true_labels, predicted_labels)\n",
        "print(\"Classification Report:\",)\n",
        "print (result1)\n",
        "print('\\n')\n",
        "g_result2 = accuracy_score(true_labels,predicted_labels)\n",
        "print(\"Accuracy:\",g_result2)\n",
        "print('\\n')\n",
        "# calculate precision and recall scores\n",
        "g_precision = precision_score(true_labels, predicted_labels)\n",
        "g_recall = recall_score(true_labels, predicted_labels)\n",
        "g_f1score = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# print the results\n",
        "print(\"Precision:\", g_precision)\n",
        "print(\"Recall:\", g_recall)\n",
        "print(\"f1 score:\", g_f1score)\n",
        "\n",
        "print(roc_auc_score(true_labels, predicted_labels))\n",
        "\n",
        "fpr, tpr, _ = roc_curve(true_labels, predicted_labels)\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X8yuErRAxr6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define the models and their performance metrics\n",
        "models = ['KNN', 'XGBRFClassifier', 'Decision Tree', 'Graph Convolution Network']\n",
        "accuracy = [k_result2, x_result2, d_result2, g_result2]\n",
        "precision = [k_precision, x_precision, d_precision, g_precision]\n",
        "recall = [k_recall, x_recall, d_recall, g_recall]\n",
        "f1_score = [k_f1score, x_f1score, d_f1score, g_f1score]\n",
        "\n",
        "# Create a single plot for all metrics using grouped bar chart\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "fig.suptitle('Model Performance Comparison Across Metrics')\n",
        "\n",
        "# Set the positions and width for the bars\n",
        "pos = np.arange(len(models))\n",
        "bar_width = 0.2\n",
        "\n",
        "# Plot bars for each metric\n",
        "rects1 = ax.bar(pos - bar_width*1.5, accuracy, bar_width, label='Accuracy', color='blue')\n",
        "rects2 = ax.bar(pos - bar_width/2, precision, bar_width, label='Precision', color='green')\n",
        "rects3 = ax.bar(pos + bar_width/2, recall, bar_width, label='Recall', color='red')\n",
        "rects4 = ax.bar(pos + bar_width*1.5, f1_score, bar_width, label='F1 Score', color='purple')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_xlabel('Models')\n",
        "ax.set_ylabel('Metrics Value')\n",
        "ax.set_xticks(pos)\n",
        "ax.set_xticklabels(models)\n",
        "ax.set_ylim([0.7, 1.0])\n",
        "ax.legend()\n",
        "\n",
        "# Label with specially formatted floats\n",
        "ax.bar_label(rects1, fmt='%.3f')\n",
        "ax.bar_label(rects2, fmt='%.3f')\n",
        "ax.bar_label(rects3, fmt='%.3f')\n",
        "ax.bar_label(rects4, fmt='%.3f')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jKM7XWg6P7aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchviz"
      ],
      "metadata": {
        "id": "d2lwCGHSBvea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchviz import make_dot\n",
        "from IPython.display import Image\n",
        "import os\n",
        "\n",
        "# Initialize the model\n",
        "GN_model = GNNModel(data_scaled.num_node_features)\n",
        "\n",
        "# Generate dummy output using a sample from your dataset\n",
        "dummy_output = GN_model(data_scaled)\n",
        "\n",
        "# Generate the visualization\n",
        "dot = make_dot(dummy_output, params=dict(GN_model.named_parameters()))\n",
        "\n",
        "# Save and display\n",
        "dot.format = 'png'\n",
        "dot.render(filename='architecture', directory='./', cleanup=True)\n",
        "display(Image(filename='architecture.png'))\n"
      ],
      "metadata": {
        "id": "4qHkdwpTBpi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hiddenlayer\n"
      ],
      "metadata": {
        "id": "3YGg3kXHMd4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparisions"
      ],
      "metadata": {
        "id": "IFjh76d09u34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to plot the combined ROC curves\n",
        "def plot_combined_roc(y_test, *models):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    for model_predictions, model_name in models:\n",
        "        fpr, tpr, _ = roc_curve(y_test, model_predictions)\n",
        "        plt.plot(fpr, tpr, label=f'{model_name}')\n",
        "\n",
        "    # Formatting\n",
        "    plt.plot([0, 1], [0, 1], 'k--')  # diagonal 45 degree line\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate (FPR)')\n",
        "    plt.ylabel('True Positive Rate (TPR)')\n",
        "    plt.title('Combined ROC Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(alpha=0.2)\n",
        "    plt.show()\n",
        "\n",
        "# Call the function after predictions for each model are available\n",
        "plot_combined_roc(y_test,\n",
        "                  (xgb_test_predictions, \"XGBoost\"),\n",
        "                  (knn_test_predictions, \"KNN\"),\n",
        "                  (dt_test_predictions, \"Decision Tree\"),\n",
        "                  (predicted_labels, \"GNN\"))  # assuming 'predicted_labels' is the GNN's predictions\n"
      ],
      "metadata": {
        "id": "P3eCjclh9wvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MPNN"
      ],
      "metadata": {
        "id": "OcBFP8am_kUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import MessagePassing"
      ],
      "metadata": {
        "id": "IbDuu2DY_jn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MPNNLayer(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(MPNNLayer, self).__init__(aggr='mean')  # \"Mean\" aggregation.\n",
        "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
        "        self.act = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # x has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E]\n",
        "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
        "\n",
        "    def message(self, x_j, edge_index, size):\n",
        "        # x_j has shape [E, in_channels]\n",
        "        x_j = self.lin(x_j)\n",
        "        x_j = self.act(x_j)\n",
        "        return x_j\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        # aggr_out has shape [N, out_channels]\n",
        "        return aggr_out"
      ],
      "metadata": {
        "id": "eYYasMuL_pgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MPNNModel(torch.nn.Module):\n",
        "    def __init__(self, num_node_features):\n",
        "        super(MPNNModel, self).__init__()\n",
        "        self.layer1 = MPNNLayer(num_node_features, 64)  # Increase to 64 nodes\n",
        "        self.layer2 = MPNNLayer(64, 32)  # New layer\n",
        "        self.layer3 = MPNNLayer(32, 32)  # New layer\n",
        "        self.layer4 = MPNNLayer(32, 16)  # Reduce to 16 nodes\n",
        "        self.layer5 = MPNNLayer(16, 2)   # Output layer for binary classification\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.layer1(x, edge_index))\n",
        "        x = F.relu(self.layer2(x, edge_index))\n",
        "        x = F.relu(self.layer3(x, edge_index))\n",
        "        x = F.relu(self.layer4(x, edge_index))\n",
        "        x = self.layer5(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "a8RGvRwR_yFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model and optimizer\n",
        "MPNN_model = MPNNModel(data_scaled.num_node_features)\n",
        "optimizer = torch.optim.Adam(MPNN_model.parameters(), lr=0.001)\n",
        "# Initialize the SGD optimizer with momentum\n",
        "\n",
        "# Lists to hold loss and precision values for plotting or analysis\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_precisions = []\n",
        "val_precisions = []\n",
        "\n",
        "# Training loop with validation\n",
        "for epoch in range(200):\n",
        "    MPNN_model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = MPNN_model(data_scaled)\n",
        "\n",
        "    # Training loss\n",
        "    train_loss = F.nll_loss(out[data_scaled.train_mask], data_scaled.y[data_scaled.train_mask])\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate training precision\n",
        "    _, train_pred = out[data_scaled.train_mask].max(dim=1)\n",
        "    train_true = data_scaled.y[data_scaled.train_mask]\n",
        "    train_precision = precision_score(train_true.cpu(), train_pred.cpu(), average='micro')\n",
        "\n",
        "    # Validation\n",
        "    MPNN_model.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():  # Deactivate autograd engine to reduce memory usage and speed up computations\n",
        "        val_loss = F.nll_loss(out[data_scaled.val_mask], data_scaled.y[data_scaled.val_mask])\n",
        "\n",
        "        # Calculate validation precision\n",
        "        _, val_pred = out[data_scaled.val_mask].max(dim=1)\n",
        "        val_true = data_scaled.y[data_scaled.val_mask]\n",
        "        val_precision = precision_score(val_true.cpu(), val_pred.cpu(), average='micro')\n",
        "\n",
        "    # Print the metrics\n",
        "    print(f\"Epoch {epoch+1}, Training Loss: {train_loss.item()}, Validation Loss: {val_loss.item()}, Training Precision: {train_precision}, Validation Precision: {val_precision}\")"
      ],
      "metadata": {
        "id": "_z7G1vFR_0nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install explaineddashboard"
      ],
      "metadata": {
        "id": "VQ8D4vlXAJUM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}